# ë”¥ëŸ¬ë‹ ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ê°€ì´ë“œ

## ğŸ¤– **ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ**

### **1. U-Net (ì¶”ì²œ) â­â­â­â­â­**
**ì¥ì :**
- ğŸ¯ **í”½ì…€ ë‹¨ìœ„ ì •í™•ë„**: ë¶ˆëŸ‰ í”½ì…€ì˜ ì •í™•í•œ ìœ„ì¹˜ íŒŒì•…
- ğŸ”¬ **ì˜ë£Œ ì˜ìƒ íŠ¹í™”**: ê²°í•¨ íƒì§€ì— ìµœì í™”
- ğŸ“ **ì„¸ë°€í•œ ë¶„ì„**: í”½ì…€ ë‹¨ìœ„ ì„¸ë°€í•œ ë¶„í• 
- ğŸ¥ **ê²€ì¦ëœ ì„±ëŠ¥**: ì˜ë£Œ ì˜ìƒì—ì„œ ê²€ì¦ëœ ì„±ëŠ¥

**ë‹¨ì :**
- ğŸŒ **ì†ë„**: ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼
- ğŸ’¾ **ë©”ëª¨ë¦¬**: ë†’ì€ ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­

**ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ì í•©ë„: â­â­â­â­â­**

### **2. YOLO â­â­â˜†â˜†â˜†**
**ì¥ì :**
- âš¡ **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ë§¤ìš° ë¹ ë¥¸ ì¶”ë¡  ì†ë„
- ğŸ¯ **ë‹¨ì¼ ë‹¨ê³„**: Detectionê³¼ Classificationì„ ë™ì‹œì—
- ğŸ“± **ê²½ëŸ‰í™”**: ëª¨ë°”ì¼/ì„ë² ë””ë“œ í™˜ê²½ì— ì í•©

**ë‹¨ì :**
- ğŸ” **ì‘ì€ ê°ì²´**: í”½ì…€ ë‹¨ìœ„ ì‘ì€ ê°ì²´ ê°ì§€ ì–´ë ¤ì›€
- ğŸ“ **í•´ìƒë„**: ê³ í•´ìƒë„ ì´ë¯¸ì§€ì—ì„œ ì„±ëŠ¥ ì €í•˜

**ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ì í•©ë„: â­â­â˜†â˜†â˜†**

### **3. Faster R-CNN â­â­â­â­â˜†**
**ì¥ì :**
- ğŸ¯ **ì •í™•ë„**: ë†’ì€ ì •í™•ë„ë¡œ ì‘ì€ ê°ì²´ ê°ì§€
- ğŸ” **ì„¸ë°€í•¨**: í”½ì…€ ë‹¨ìœ„ ì„¸ë°€í•œ ë¶„ì„ ê°€ëŠ¥
- ğŸ“Š **ì„±ëŠ¥**: ê²€ì¦ëœ 2-stage ì•Œê³ ë¦¬ì¦˜

**ë‹¨ì :**
- ğŸŒ **ì†ë„**: ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦° ì²˜ë¦¬ ì†ë„
- ğŸ’¾ **ë©”ëª¨ë¦¬**: ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

**ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ì í•©ë„: â­â­â­â­â˜†**

### **4. Mask R-CNN â­â­â­â­â˜†**
**ì¥ì :**
- ğŸ¯ **ì •í™•ë„**: ë§¤ìš° ë†’ì€ ì •í™•ë„
- ğŸ” **ì„¸ë°€í•¨**: í”½ì…€ ë‹¨ìœ„ ì •í™•í•œ ë¶„í• 
- ğŸ“Š **ì„±ëŠ¥**: ê²€ì¦ëœ 3-stage ì•Œê³ ë¦¬ì¦˜

**ë‹¨ì :**
- ğŸŒ **ì†ë„**: ê°€ì¥ ëŠë¦° ì²˜ë¦¬ ì†ë„
- ğŸ’¾ **ë©”ëª¨ë¦¬**: ë§¤ìš° ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

**ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ì í•©ë„: â­â­â­â­â˜†**

## ğŸ† **ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜: U-Net**

### **ì´ìœ :**
1. **í”½ì…€ ë‹¨ìœ„ ì •í™•ë„**: ë¶ˆëŸ‰ í”½ì…€ì˜ ì •í™•í•œ ìœ„ì¹˜ íŒŒì•…
2. **ì˜ë£Œ ì˜ìƒ íŠ¹í™”**: ê²°í•¨ íƒì§€ì— ìµœì í™”
3. **ì„¸ë°€í•œ ë¶„ì„**: í”½ì…€ ë‹¨ìœ„ ì„¸ë°€í•œ ë¶„í• 
4. **ê²€ì¦ëœ ì„±ëŠ¥**: ì˜ë£Œ ì˜ìƒì—ì„œ ê²€ì¦ëœ ì„±ëŠ¥

## ğŸ› ï¸ **êµ¬í˜„ ë°©ë²•**

### **1. U-Net ì•„í‚¤í…ì²˜**
```python
class UNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(UNet, self).__init__()
        
        # Encoder (ë‹¤ìš´ìƒ˜í”Œë§)
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        
        # Bottleneck
        self.bottleneck = self.conv_block(512, 1024)
        
        # Decoder (ì—…ìƒ˜í”Œë§)
        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(1024, 512)
        
        # ... (ë‚˜ë¨¸ì§€ decoder layers)
        
        # Final layer
        self.final = nn.Conv2d(64, out_channels, kernel_size=1)
```

### **2. ë°ì´í„° ì „ì²˜ë¦¬**
```python
transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                       std=[0.229, 0.224, 0.225])
])
```

### **3. í›ˆë ¨ ì„¤ì •**
```python
# ì†ì‹¤ í•¨ìˆ˜
criterion = nn.BCELoss()

# ì˜µí‹°ë§ˆì´ì €
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)
```

## ğŸ“Š **ì„±ëŠ¥ ë¹„êµ**

### **ì†ë„ (FPS)**
- **U-Net**: 15-20 FPS
- **YOLO**: 30-60 FPS
- **Faster R-CNN**: 5-10 FPS
- **Mask R-CNN**: 2-5 FPS

### **ì •í™•ë„ (mIoU)**
- **U-Net**: 0.85-0.95
- **YOLO**: 0.60-0.75
- **Faster R-CNN**: 0.80-0.90
- **Mask R-CNN**: 0.85-0.95

### **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**
- **U-Net**: 4-8 GB
- **YOLO**: 2-4 GB
- **Faster R-CNN**: 6-12 GB
- **Mask R-CNN**: 8-16 GB

## ğŸ¯ **ë¶ˆëŸ‰ í”½ì…€ íƒì§€ ìµœì í™”**

### **1. ë°ì´í„° ì¦ê°•**
```python
augmentation = transforms.Compose([
    transforms.RandomRotation(10),
    transforms.RandomHorizontalFlip(0.5),
    transforms.RandomVerticalFlip(0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))
])
```

### **2. ì†ì‹¤ í•¨ìˆ˜ ìµœì í™”**
```python
# Dice Loss for ë¶ˆëŸ‰ í”½ì…€ íƒì§€
def dice_loss(pred, target, smooth=1e-5):
    pred = torch.sigmoid(pred)
    intersection = (pred * target).sum()
    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    return 1 - dice
```

### **3. í›„ì²˜ë¦¬ ìµœì í™”**
```python
def post_process(mask, min_area=50, min_aspect_ratio=2.0):
    # ë…¸ì´ì¦ˆ ì œê±°
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    # ìµœì†Œ ë©´ì  í•„í„°ë§
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    filtered_contours = [c for c in contours if cv2.contourArea(c) > min_area]
    
    # ì¢…íš¡ë¹„ í•„í„°ë§
    final_contours = []
    for contour in filtered_contours:
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = max(w, h) / min(w, h)
        if aspect_ratio > min_aspect_ratio:
            final_contours.append(contour)
    
    return final_contours
```

## ğŸš€ **ì‹¤ì œ êµ¬í˜„ ë‹¨ê³„**

### **1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„**
```bash
# í›ˆë ¨ ë°ì´í„° êµ¬ì¡°
data/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ normal_001.jpg
â”‚   â”œâ”€â”€ normal_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ masks/
â”‚   â”œâ”€â”€ normal_001_mask.png
â”‚   â”œâ”€â”€ normal_002_mask.png
â”‚   â””â”€â”€ ...
â””â”€â”€ annotations.json
```

### **2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨**
```python
# í›ˆë ¨ ë£¨í”„
for epoch in range(num_epochs):
    model.train()
    for batch_idx, (images, masks) in enumerate(dataloader):
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
```

### **3ë‹¨ê³„: ëª¨ë¸ í‰ê°€**
```python
# í‰ê°€ ë©”íŠ¸ë¦­
def evaluate_model(model, dataloader):
    model.eval()
    total_iou = 0
    total_dice = 0
    
    with torch.no_grad():
        for images, masks in dataloader:
            outputs = model(images)
            iou = calculate_iou(outputs, masks)
            dice = calculate_dice(outputs, masks)
            total_iou += iou
            total_dice += dice
    
    return total_iou / len(dataloader), total_dice / len(dataloader)
```

## ğŸ“ˆ **ì„±ëŠ¥ í–¥ìƒ íŒ**

### **1. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
- **í•™ìŠµë¥ **: 0.001 â†’ 0.0001
- **ë°°ì¹˜ í¬ê¸°**: 4 â†’ 8 â†’ 16
- **ì—í¬í¬**: 50 â†’ 100 â†’ 200

### **2. ëª¨ë¸ ì•™ìƒë¸”**
```python
# ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©
def ensemble_predict(models, image):
    predictions = []
    for model in models:
        pred = model(image)
        predictions.append(pred)
    
    # í‰ê·  ë˜ëŠ” íˆ¬í‘œ
    final_pred = torch.mean(torch.stack(predictions), dim=0)
    return final_pred
```

### **3. ì „ì´ í•™ìŠµ**
```python
# ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©
pretrained_model = torchvision.models.segmentation.deeplabv3_resnet50(
    pretrained=True, progress=True
)

# ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ ì¬í›ˆë ¨
for param in pretrained_model.parameters():
    param.requires_grad = False

# ë¶„ë¥˜ê¸°ë§Œ ì¬í›ˆë ¨
pretrained_model.classifier = nn.Conv2d(2048, 1, kernel_size=1)
```

## ğŸ¯ **ê²°ë¡ **

### **ë¶ˆëŸ‰ í”½ì…€ íƒì§€ì— ìµœì í™”ëœ ì•Œê³ ë¦¬ì¦˜:**
1. **U-Net**: í”½ì…€ ë‹¨ìœ„ ì •í™•ë„, ì˜ë£Œ ì˜ìƒ íŠ¹í™”
2. **Faster R-CNN**: ë†’ì€ ì •í™•ë„, ì‘ì€ ê°ì²´ ê°ì§€
3. **Mask R-CNN**: ë§¤ìš° ë†’ì€ ì •í™•ë„, ì •í™•í•œ ë¶„í• 

### **ì‹¤ì œ êµ¬í˜„ ê¶Œì¥ì‚¬í•­:**
- **U-Net**ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
- **ì „ì´ í•™ìŠµ**ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
- **ë°ì´í„° ì¦ê°•**ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- **ì•™ìƒë¸”**ë¡œ ìµœì¢… ì„±ëŠ¥ í–¥ìƒ

### **ì„±ëŠ¥ ëª©í‘œ:**
- **ì •í™•ë„**: 95% ì´ìƒ
- **ì†ë„**: 15-20 FPS
- **ë©”ëª¨ë¦¬**: 4-8 GB
- **ì‹ ë¢°ë„**: 0.9 ì´ìƒ
